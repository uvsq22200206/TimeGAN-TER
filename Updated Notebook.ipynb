{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeGAN\n",
    "The following notebook is for the use during the TER project (2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Generator and Discriminator for TimeGAN are using a RNN, but we were unable to replicate the results found in the paper (J. Yoon) with the Gated Recurring Unit (GRU) Neural Network.\n",
    "In the following code, we are going to use Long Short-Term Memory RNN instead of GRU to check whether the results can be replicated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Necessary packages\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1. TimeGAN model\n",
    "from timegan import timegan\n",
    "\n",
    "# 2. Data loading\n",
    "from data_loading import real_data_loading, sine_data_generation, MinMaxScaler\n",
    "#An issue showed up when trying to import the Google Stock data, hence why we needed to import MinMaxScaler from data_loading.py\n",
    "\n",
    "# 3. Metrics\n",
    "from metrics.discriminative_metrics import discriminative_score_metrics\n",
    "from metrics.predictive_metrics import predictive_score_metrics\n",
    "from metrics.visualization_metrics import visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading: Google Stock\n",
    "\n",
    "data_name: google\n",
    "\n",
    "seq_len: sequence length of the time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Stock dataset is ready.\n"
     ]
    }
   ],
   "source": [
    "def google_data_loading(seq_length):\n",
    "\n",
    "    # Load Google Data\n",
    "    x = np.loadtxt('data/GOOG.csv', delimiter = \",\",skiprows = 1, usecols=range(1,6)) #modified this to ignore the date column\n",
    "    # Flip the data to make chronological data\n",
    "    x = x[::-1]\n",
    "    # Min-Max Normalizer\n",
    "    x = MinMaxScaler(x)\n",
    "    \n",
    "    # Build dataset\n",
    "    dataX = []\n",
    "    \n",
    "    # Cut data by sequence length\n",
    "    for i in range(0, len(x) - seq_length):\n",
    "        _x = x[i:i + seq_length]\n",
    "        dataX.append(_x)\n",
    "        \n",
    "    # Mix Data (to make it similar to i.i.d)\n",
    "    idx = np.random.permutation(len(dataX))\n",
    "    \n",
    "    outputX = []\n",
    "    for i in range(len(dataX)):\n",
    "        outputX.append(dataX[idx[i]])\n",
    "    \n",
    "    return outputX\n",
    "\n",
    "#Loading the Google Stock Data using the function defined above.\n",
    "\n",
    "seq_len = 24\n",
    "ori_data = google_data_loading(seq_len)\n",
    "    \n",
    "print('Google Stock dataset is ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Network Parameters:\n",
    "\n",
    "module: gru, lstm, or lstmLN\n",
    "\n",
    "hidden_dim: hidden dimensions\n",
    "\n",
    "num_layer: number of layers\n",
    "\n",
    "iteration: number of training iterations\n",
    "\n",
    "batch_size: the number of samples in each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Newtork parameters\n",
    "parameters = dict()\n",
    "\n",
    "parameters['module'] = 'lstm' \n",
    "parameters['hidden_dim'] = 24\n",
    "parameters['num_layer'] = 2 #2 layer LSTM\n",
    "parameters['iterations'] = 10000\n",
    "parameters['batch_size'] = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Real Work (Running TimeGAN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run TimeGAN\n",
    "generated_data = timegan(ori_data, parameters)   \n",
    "print('Finish Synthetic Data Generation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
